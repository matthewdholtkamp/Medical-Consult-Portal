<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. H - Clinical Consultant</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Marked.js for Markdown Parsing -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        gemini: {
                            800: '#1e293b',
                            900: '#0f172a',
                        },
                        bloomberg: {
                            white: '#ffffff',
                            gray: '#f3f4f6',
                            text: '#111827',
                            border: '#e5e7eb',
                            accent: '#0057b7' // Classic Blue
                        }
                    },
                    animation: {
                        'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',
                        'bounce-slow': 'bounce 1.5s infinite',
                    }
                }
            }
        }
    </script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />

    <style>
        body { font-family: 'Inter', sans-serif; }

        /* Audio Pulse Animation */
        @keyframes pulse-ring {
            0% { transform: scale(0.8); opacity: 0.5; }
            100% { transform: scale(2.2); opacity: 0; }
        }
        
        .pulse-active::before {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        
        .pulse-active::after {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
            animation-delay: 0.5s;
        }

        @keyframes think-glow {
            0%, 100% { box-shadow: 0 0 20px rgba(168, 85, 247, 0.2); border-color: rgba(168, 85, 247, 0.5); }
            50% { box-shadow: 0 0 40px rgba(168, 85, 247, 0.6); border-color: rgba(168, 85, 247, 1); }
        }
        .thinking-active {
            animation: think-glow 2s infinite;
        }

        /* 3-Dots Typing Indicator */
        .typing-dot {
            animation: typing 1.4s infinite ease-in-out both;
        }
        .typing-dot:nth-child(1) { animation-delay: -0.32s; }
        .typing-dot:nth-child(2) { animation-delay: -0.16s; }

        @keyframes typing {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1); }
        }

        .background-overlay {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle at 2px 2px, rgba(148, 163, 184, 0.15) 1px, transparent 0); /* Visible in Light */
            background-size: 32px 32px;
            opacity: 0.5; 
            pointer-events: none; 
        }
        .dark .background-overlay {
             background-image: radial-gradient(circle at 2px 2px, rgba(255,255,255,0.05) 1px, transparent 0);
        }

        .chat-message {
            opacity: 0;
            animation: fadeIn 0.3s forwards;
        }
        @keyframes fadeIn { to { opacity: 1; } }
        
        /* Custom scrollbar for chat */
        .custom-scroll::-webkit-scrollbar { width: 6px; }
        .custom-scroll::-webkit-scrollbar-track { background: transparent; }
        .custom-scroll::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 3px; }
        .dark .custom-scroll::-webkit-scrollbar-thumb { background: #334155; }
        
        /* Dictation Pulse */
        @keyframes dictation-pulse {
            0% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.2); opacity: 0.8; }
            100% { transform: scale(1); opacity: 1; }
        }
        .dictating {
            animation: dictation-pulse 1.5s infinite;
            color: #ef4444 !important; /* Red */
        }

        /* Simple Prose for Markdown Content - Modernized for Readability */
        .prose-content { font-size: 0.95rem; }
        .prose-content ul { list-style-type: disc; padding-left: 1.5rem; margin-top: 0.75rem; margin-bottom: 0.75rem; color: #cbd5e1; }
        .prose-content ol { list-style-type: decimal; padding-left: 1.5rem; margin-top: 0.75rem; margin-bottom: 0.75rem; color: #cbd5e1; }
        .prose-content p { margin-bottom: 1rem; line-height: 1.75; color: #e2e8f0; }
        .prose-content strong { color: #60a5fa; font-weight: 700; }
        .prose-content h1 { color: #f8fafc; font-weight: 700; font-size: 1.25rem; margin-top: 1.75rem; margin-bottom: 1rem; border-bottom: 1px solid rgba(255,255,255,0.1); padding-bottom: 0.5rem; }
        .prose-content h2 { color: #f1f5f9; font-weight: 600; font-size: 1.1rem; margin-top: 1.5rem; margin-bottom: 0.75rem; }
        .prose-content h3 { color: #e2e8f0; font-weight: 600; font-size: 1rem; margin-top: 1.25rem; margin-bottom: 0.5rem; text-transform: uppercase; letter-spacing: 0.05em; font-size: 0.85rem; }
        .prose-content li { margin-bottom: 0.35rem; line-height: 1.6; }
        .prose-content blockquote { border-left: 4px solid #ef4444; background: rgba(239, 68, 68, 0.1); padding: 0.75rem 1rem; margin: 1rem 0; border-radius: 0 0.5rem 0.5rem 0; color: #fecaca; font-style: italic; }
        /* Fix for superscripts in prose */
        .prose-content sup { color: #3b82f6; font-weight: 600; font-size: 0.75em; margin-left: 1px; vertical-align: super; }

        /* Toggle Switch CSS */
        .toggle-checkbox:checked {
            right: 0;
            border-color: #68D391;
        }
        .toggle-checkbox:checked + .toggle-label {
            background-color: #68D391;
        }

        .toggle-switch-container {
            display: inline-flex;
            align-items: center;
            cursor: pointer;
        }
    </style>
</head>

<body class="bg-bloomberg-gray dark:bg-gemini-900 text-bloomberg-text dark:text-gray-200 h-screen overflow-hidden flex flex-col relative selection:bg-blue-500 selection:text-white transition-colors duration-300">

    <div class="background-overlay"></div>

    <!-- Header -->
    <header class="h-16 flex items-center justify-between px-4 sm:px-6 z-20 border-b border-bloomberg-border dark:border-white/5 bg-white/80 dark:bg-gemini-900/50 backdrop-blur-sm flex-shrink-0 transition-colors duration-300">
        <div class="flex items-center gap-3">
            <div class="w-8 h-8 rounded-lg bg-gradient-to-br from-blue-600 to-indigo-700 flex items-center justify-center shadow-lg shadow-blue-500/20">
                <span class="material-symbols-outlined text-white text-[20px]">medical_services</span>
            </div>
            <div class="hidden sm:block">
                <h1 class="font-bold text-slate-800 dark:text-slate-100 text-sm tracking-wide">Dr. Holtkamp</h1>
                <p class="text-[10px] text-slate-500 uppercase tracking-wider font-medium">Expert Clinical Consultant</p>
            </div>
        </div>

        <!-- Right Side Controls (Audio + Theme) -->
        <div class="flex items-center gap-4">

            <!-- Audio Toggle Switch -->
            <label class="toggle-switch-container flex items-center gap-2 cursor-pointer group">
                <div class="relative">
                    <input type="checkbox" id="audio-toggle" class="sr-only peer">
                    <div class="w-9 h-5 bg-slate-300 dark:bg-slate-700 peer-focus:outline-none rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-4 after:w-4 after:transition-all dark:border-gray-600 peer-checked:bg-blue-600"></div>
                </div>
                <span class="text-xs font-medium text-slate-500 dark:text-slate-400 group-hover:text-slate-800 dark:group-hover:text-slate-200 transition-colors hidden sm:inline-block">Generate Audio</span>
                <span class="material-symbols-outlined text-slate-500 text-lg sm:hidden">volume_up</span>
            </label>

            <!-- Audio Controls (Independent) - Moved to Header -->
            <div id="audio-controls" class="hidden flex items-center gap-2 p-1 bg-slate-100 dark:bg-slate-800/50 rounded-full border border-slate-200 dark:border-slate-700/50 backdrop-blur-sm transition-all">
                <button onclick="window.playAudio()" class="p-1 rounded-full hover:bg-slate-200 dark:hover:bg-slate-700 text-green-600 dark:text-green-400 transition-colors" title="Play Audio">
                    <span class="material-symbols-outlined text-xl">play_circle</span>
                </button>
                <button onclick="window.pauseAudio()" class="p-1 rounded-full hover:bg-slate-200 dark:hover:bg-slate-700 text-amber-600 dark:text-amber-400 transition-colors" title="Pause Audio">
                    <span class="material-symbols-outlined text-xl">pause_circle</span>
                </button>
            </div>

            <div class="h-6 w-px bg-slate-300 dark:bg-slate-700 mx-1"></div>

             <!-- Theme Toggle -->
            <button id="theme-toggle" onclick="toggleTheme()" class="p-2 rounded-full hover:bg-slate-200 dark:hover:bg-slate-800 transition-colors text-slate-600 dark:text-slate-400">
                <span class="material-symbols-outlined" id="theme-icon">light_mode</span>
            </button>
        </div>
    </header>

    <!-- Main Content: Flex Column Layout for Stability -->
    <main class="flex-1 flex flex-col overflow-hidden relative z-10">
        
        <!-- Conversation Log: Flex Grow to Fill Space -->
        <div id="conversation-container" class="flex-1 overflow-y-auto px-4 py-6 space-y-4 custom-scroll">
            <div class="text-center text-slate-400 dark:text-slate-500 text-xs mt-4 uppercase tracking-widest font-semibold">Session Started</div>
            <!-- Messages injected here -->
        </div>

        <!-- Input Area: Stays at Bottom Naturally -->
        <div class="bg-white/90 dark:bg-slate-900/90 backdrop-blur-md border-t border-slate-200 dark:border-slate-800 p-4 pb-4 flex-shrink-0 flex flex-col gap-3 transition-colors duration-300">
            
            <!-- Canvas Visualizer -->
            <div class="flex items-center justify-center h-12 w-full max-w-lg mx-auto opacity-50 transition-opacity duration-300" id="visualizer-container">
                <canvas id="audio-visualizer" width="400" height="48" class="w-full h-full"></canvas>
            </div>

            <!-- Input Bar -->
            <div class="max-w-3xl mx-auto w-full flex items-end gap-2 bg-slate-100 dark:bg-slate-800 p-2 rounded-3xl border border-slate-300 dark:border-slate-700 shadow-sm dark:shadow-lg focus-within:ring-2 focus-within:ring-blue-500/50 transition-all">
                
                <!-- Main Voice Mode Button (Conversation) -->
                <button onclick="handleMicToggle()" id="main-mic-btn" class="w-10 h-10 mb-0.5 rounded-full bg-slate-200 dark:bg-slate-700 hover:bg-slate-300 dark:hover:bg-slate-600 flex items-center justify-center transition-colors flex-shrink-0 group" title="Hold Conversation">
                    <span class="material-symbols-outlined text-slate-600 dark:text-slate-300 group-hover:text-black dark:group-hover:text-white transition-colors" id="mic-icon">record_voice_over</span>
                </button>

                <!-- Expanding Text Input -->
                <textarea id="text-input" rows="1" placeholder="Type query or tap mic to speak..." class="flex-1 bg-transparent border-none outline-none text-sm text-slate-900 dark:text-white px-2 py-2.5 font-medium placeholder:text-slate-400 resize-none overflow-hidden max-h-32" onkeydown="handleInputKey(event)"></textarea>

                <!-- Send Button -->
                <button onclick="handleTextSubmit()" class="w-10 h-10 mb-0.5 rounded-full bg-blue-600 hover:bg-blue-500 flex items-center justify-center transition-colors flex-shrink-0 shadow-md">
                    <span class="material-symbols-outlined text-white text-lg">arrow_upward</span>
                </button>
            </div>
            
            <div class="text-center h-4">
                <span id="interaction-status" class="text-[10px] font-bold tracking-widest text-slate-400 dark:text-slate-500 uppercase transition-colors">Ready</span>
            </div>
        </div>

    </main>

    <!-- PCM to WAV Library (Inlined for single file portability) -->
    <script>
    !function(e,t){"object"==typeof exports&&"object"==typeof module?module.exports=t():"function"==typeof define&&define.amd?define([],t):"object"==typeof exports?exports.pcmToWav=t():e.pcmToWav=t()}(window,function(){return function(e){var t={};function r(n){if(t[n])return t[n].exports;var o=t[n]={i:n,l:!1,exports:{}};return e[n].call(o.exports,o,o.exports,r),o.l=!0,o.exports}return r.m=e,r.c=t,r.d=function(e,t,n){r.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},r.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},r.t=function(e,t){if(1&t&&(e=r(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(r.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)r.d(n,o,function(t){return e[t]}.bind(null,o));return n},r.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(t,"a",t),t},r.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},r.p="",r(r.s=0)}([function(e,t,r){"use strict";Object.defineProperty(t,"__esModule",{value:!0}),t.default=function(e,t,r){var n,o,a,i,f,c,u,d=new DataView(new ArrayBuffer(44+e.length*t*2));return d.setUint32(0,1380533830,!1),d.setUint32(4,36+e.length*t*2,!0),d.setUint32(8,1463899717,!1),d.setUint32(12,1718449184,!1),d.setUint32(16,16,!0),d.setUint16(20,1,!0),n=t,d.setUint16(22,n,!0),o=r,d.setUint32(24,o,!0),a=r*t*2,d.setUint32(28,a,!0),i=2*t,d.setUint16(32,i,!0),f=16,d.setUint16(34,f,!0),d.setUint32(36,1684108385,!1),c=e.length*t*2,d.setUint32(40,c,!0),u=new Uint8Array(d.buffer,44),e.forEach(function(e,t){var r=44+2*t;d.setInt16(r,e,!0)}),new Blob([d.buffer],{type:"audio/wav"})},e.exports=t.default}])});
    </script>

    <script type="module">
        import { API_KEYS } from './js/config.js?v=secure';
        import { COV_INSTRUCTIONS } from './js/prompts.js';

        // --- Configuration ---
        let API_KEY = API_KEYS.PSYCHIATRY;
        const MODEL_ID = "gemini-2.5-flash"; // Main chat model
        const TTS_MODEL_ID = "gemini-2.5-flash-preview-tts"; // Model for Audio Generation (Aoede)
        
        // --- State Machine ---
        const STATE = {
            IDLE: 'IDLE',
            LISTENING: 'LISTENING',
            THINKING: 'THINKING',
            GENERATING_VOICE: 'GENERATING_VOICE',
            SPEAKING: 'SPEAKING',
            ERROR: 'ERROR'
        };
        let currentState = STATE.IDLE;

        // --- Globals ---
        let recognition = null; // Web Speech API
        let audioContext = null; // Visualizer
        let analyser = null;
        let microphoneStream = null;
        let dataArray = null;
        let animationFrame = null;
        let currentAudio = null; // For native TTS playback
        let conversationHistory = []; 
        let isDictating = false; // Flag to keep mic alive

        // Visualizer Canvas
        const canvas = document.getElementById('audio-visualizer');
        const canvasCtx = canvas.getContext('2d');

        // --- UI References ---
        const ui = {
            btn: document.getElementById('main-mic-btn'),
            icon: document.getElementById('mic-icon'),
            statusText: document.getElementById('status-text'), // No longer exists in header, handled in updateState differently? No, I removed it. Need to fix references.
            interactionText: document.getElementById('interaction-status'),
            visualizerContainer: document.getElementById('visualizer-container'),
            conversation: document.getElementById('conversation-container'),
            textInput: document.getElementById('text-input'),
            audioControls: document.getElementById('audio-controls'),
            audioToggle: document.getElementById('audio-toggle'),
            themeIcon: document.getElementById('theme-icon')
        };

        // --- Theme Toggle ---
        window.toggleTheme = function() {
            const html = document.documentElement;
            if (html.classList.contains('dark')) {
                html.classList.remove('dark');
                ui.themeIcon.innerText = "dark_mode";
                localStorage.setItem('theme', 'light');
            } else {
                html.classList.add('dark');
                ui.themeIcon.innerText = "light_mode";
                localStorage.setItem('theme', 'dark');
            }
        }

        // Init Theme
        if (localStorage.getItem('theme') === 'light') {
            document.documentElement.classList.remove('dark');
            ui.themeIcon.innerText = "dark_mode";
        }

        // --- Auto-Resize Textarea ---
        ui.textInput.addEventListener('input', function() {
            this.style.height = 'auto';
            this.style.height = (this.scrollHeight) + 'px';
            if(this.value === '') this.style.height = 'auto'; // Reset
        });

        // --- Core Logic ---

        // --- Audio Control Logic ---
        window.playAudio = function() {
            if(currentAudio) {
                currentAudio.play().catch(e => console.warn("Play interrupted", e));
                updateState(STATE.SPEAKING);
            }
        };

        window.pauseAudio = function() {
            if(currentAudio) {
                currentAudio.pause();
                // ui.statusText.innerText = "PAUSED"; // Removed
                // ui.statusDot.className = "w-2 h-2 rounded-full bg-amber-500"; // Removed
            }
        };

        // --- Mic Logic (Live Transcription) ---
        window.handleMicToggle = function() {
            if (currentState === STATE.IDLE) {
                startDictation();
            } else if (currentState === STATE.LISTENING) {
                stopDictation();
            } else if (currentState === STATE.SPEAKING || currentState === STATE.GENERATING_VOICE) {
                // If speaking, button stops playback (legacy behavior + new stop button behavior)
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null; // "Stop" resets it
                }
                updateState(STATE.IDLE);
            }
        };

        async function startDictation() {
            isDictating = true;
            updateState(STATE.LISTENING); // Immediate UI feedback

            // 1. Start Visualizer (User Media)
            try {
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') await audioContext.resume();
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                microphoneStream = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256; // Higher res for canvas
                microphoneStream.connect(analyser);
                dataArray = new Uint8Array(analyser.frequencyBinCount);
                drawVisualizer();
            } catch(e) {
                console.warn("Visualizer failed init", e);
            }

            // 2. Start Speech Recognition
            if (!('webkitSpeechRecognition' in window)) {
                alert("Speech Recognition not supported in this browser. Use Chrome/Edge.");
                return;
            }

            // If we already have a recognition instance, stopping might trigger onend
            if (recognition) {
                recognition.stop();
            }

            const initialText = ui.textInput.value;
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
                let transcript = "";
                // Iterate over ALL results to rebuild the full transcript
                for (let i = 0; i < event.results.length; ++i) {
                    transcript += event.results[i][0].transcript;
                }

                // Append current session transcript to what was there before start
                let spacer = "";
                if (initialText && !initialText.endsWith(" ") && transcript && !transcript.startsWith(" ")) {
                    spacer = " ";
                }

                ui.textInput.value = initialText + spacer + transcript;

                // Auto-resize
                ui.textInput.style.height = 'auto';
                ui.textInput.style.height = (ui.textInput.scrollHeight) + 'px';
            };

            recognition.onerror = function(event) {
                console.warn("Speech warning", event.error);
                // Don't stop for 'no-speech' or 'aborted', just let onend restart if needed
                if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                     isDictating = false;
                     updateState(STATE.IDLE);
                }
            };

            recognition.onend = function() {
                // Auto-restart logic
                if (isDictating) {
                    console.log("Recognition ended, restarting...");
                    try {
                        recognition.start();
                    } catch (e) {
                        console.error("Restart failed", e);
                        isDictating = false;
                        updateState(STATE.IDLE);
                    }
                }
            };

            try {
                recognition.start();
            } catch (e) {
                console.error("Start failed", e);
                isDictating = false;
                updateState(STATE.IDLE);
            }
        }

        function stopDictation() {
            isDictating = false; // Kill the auto-restart loop

            if (recognition) {
                recognition.stop();
                // recognition = null; // Keep instance for onend cleanup?
            }
            // Stop Visualizer
            if (microphoneStream) {
                microphoneStream.mediaStream.getTracks().forEach(track => track.stop());
                microphoneStream.disconnect();
                microphoneStream = null;
            }

            // Submit the text
            // Small delay to let final result process
            setTimeout(() => {
                handleTextSubmit();
            }, 500);
        }

        function b64ToBytes(b64) {
          const fixed = b64.replace(/-/g, "+").replace(/_/g, "/");
          const pad = fixed.length % 4 ? "=".repeat(4 - (fixed.length % 4)) : "";
          const bin = atob(fixed + pad);
          const bytes = new Uint8Array(bin.length);
          for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
          return bytes;
        }

        window.handleInputKey = function(e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault(); // Prevent new line
                handleTextSubmit();
            }
        }

        window.handleTextSubmit = function() {
            const text = ui.textInput.value.trim();
            if (!text) return;
            
            ui.textInput.value = '';
            ui.textInput.style.height = 'auto'; // Reset height
            handleUserTurn({ text: text });
        }

        // Handles Conversation Turn (Audio or Text)
        async function handleUserTurn(input) {
            updateState(STATE.THINKING);
            let userText = input.text;
            
            // 1. Display User Input
            addMessageToLog("You", userText);

            // Add Thinking Indicator
            const thinkingId = addThinkingIndicator();

            // 2. Send TEXT to Dr. H (Gemini) for response
            try {
                const responseText = await callGeminiAPI({ text: userText });

                // Remove thinking, add response
                removeThinkingIndicator(thinkingId);
                addMessageToLog("Dr. H", responseText);

                // 3. Audio Logic (Conditional)
                const isAudioEnabled = ui.audioToggle.checked;

                if (isAudioEnabled) {
                    // Start generation immediately without waiting for user
                    speakResponseWithGemini(responseText);
                } else {
                    updateState(STATE.IDLE);
                }

            } catch (err) {
                console.error(err);
                removeThinkingIndicator(thinkingId);
                updateState(STATE.IDLE);
                
                if (err.message.includes("429")) {
                    addMessageToLog("System", "Quota Limit Reached. Please wait ~1 minute before trying again.");
                } else {
                    addMessageToLog("System", "Error: " + err.message);
                }
            }
        }

        async function callGeminiAPI(input) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/${MODEL_ID}:generateContent?key=${API_KEY}`;
            
            let userPart = { text: input.text };

            // Add user turn to history
            conversationHistory.push({
                role: "user",
                parts: [userPart]
            });

            // Using unified prompt from js/prompts.js (Chain of Verification)
            const payload = {
                contents: conversationHistory,
                systemInstruction: {
                    parts: [{ text: COV_INSTRUCTIONS }]
                }
            };

            const response = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                let details = "";
                try {
                    const j = await response.json();
                    details = j?.error?.message || JSON.stringify(j);
                } catch {
                    details = await response.text();
                }
                // Remove failed turn so retry works
                conversationHistory.pop();
                throw new Error(`API Error ${response.status}: ${details}`);
            }

            const data = await response.json();
            const text = data?.candidates?.[0]?.content?.parts
                ?.map(p => p.text)
                ?.filter(Boolean)
                ?.join("") || "";
            
            if (!text) {
                conversationHistory.pop();
                throw new Error("No response text found.");
            }
            
            // Add model response to history
            conversationHistory.push({
                role: "model",
                parts: [{ text: text }]
            });
            
            if (conversationHistory.length > 20) {
                conversationHistory = conversationHistory.slice(conversationHistory.length - 20);
            }
            
            return text;
        }

        // Generate Audio using Gemini's Aoede Voice
        async function speakResponseWithGemini(textToSpeak) {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }
            updateState(STATE.GENERATING_VOICE);

            const url = `https://generativelanguage.googleapis.com/v1beta/models/${TTS_MODEL_ID}:generateContent?key=${API_KEY}`;
            
            const ttsPayload = {
                contents: [{ parts: [{ text: textToSpeak }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: {
                                voiceName: "Aoede"
                            }
                        }
                    }
                }
            };

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(ttsPayload)
                });

                if (!response.ok) throw new Error("TTS Generation Failed");

                const data = await response.json();
                
                // Extract audio data (Base64)
                const audioData = data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
                const mimeType = data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.mimeType || "audio/pcm";
                
                if (!audioData) throw new Error("No audio returned");

                // Decode Safe Base64
                const bytes = b64ToBytes(audioData);

                // Convert/Blob
                let blob;
                if (mimeType.includes("pcm") || mimeType.includes("L16")) {
                  if (typeof window.pcmToWav !== "function") throw new Error("pcmToWav missing on globalThis");
                  // Int16Array view of the bytes
                  const pcm16 = new Int16Array(bytes.buffer);
                  blob = window.pcmToWav(pcm16, 1, 24000);
                } else {
                  blob = new Blob([bytes], { type: mimeType });
                }

                const audioUrl = URL.createObjectURL(blob);
                currentAudio = new Audio(audioUrl);
                currentAudio.playbackRate = 1.25;
                
                currentAudio.onended = () => {
                    updateState(STATE.IDLE);
                };
                
                ui.audioControls.classList.remove('hidden');

                // User Requirement: "dont start talking unless we click the play button"
                // Implementation: We generated the audio (so it's ready and fast), but we PAUSE.
                // UNLESS the user requirement said "Option B: Faster... start talking".
                // Let's re-read: "option b, i also need toggle for audio on or off"
                // AND "dont start talking unless we click the play button"

                // My interpretation:
                // 1. Generate it immediately (Option B speed)
                // 2. But DO NOT call play() automatically.
                // 3. Show the play button.

                updateState(STATE.IDLE); // Ready to play, but idle

                // We will NOT call play(). The user must click play in the top bar.
                // Wait, if I don't play, the state is IDLE, but we need to know audio is ready.
                // I will add a visual cue.

            } catch (err) {
                console.error("Gemini TTS Failed, using fallback browser TTS", err);
                updateState(STATE.IDLE);
            }
        }

        function cleanMedicalResponse(text) {
            if (!text) return "";
            let cleaned = text;
            cleaned = cleaned.replace(/\$\{\}\^\{(\d+)\}\$/g, "<sup>$1</sup>");
            cleaned = cleaned.replace(/\$\{\}\^(\d+)/g, "<sup>$1</sup>");
            cleaned = cleaned.replace(/\$\^\{?(\d+)\}?\$?/g, "<sup>$1</sup>");
            cleaned = cleaned.replace(/\$\{\^(\d+)\}\$/g, "<sup>$1</sup>");
            cleaned = cleaned.replace(/\$\_/g, "");
            return cleaned;
        }

        window.copyResponse = function(elementId) {
            const el = document.getElementById(elementId);
            if (!el) return;
            const text = el.innerText;
            navigator.clipboard.writeText(text).then(() => {
            }).catch(err => console.error('Failed to copy', err));
        };

        window.addThinkingIndicator = function() {
            const id = 'thinking-' + Date.now();
            const div = document.createElement('div');
            div.id = id;
            div.className = "bg-white/90 dark:bg-gemini-800/90 backdrop-blur-sm p-4 rounded-2xl rounded-tl-sm border border-slate-200 dark:border-blue-500/30 shadow-sm animate-fade-in mb-4 max-w-[100px] mr-auto flex items-center gap-1";

            div.innerHTML = `
                <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
                <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
                <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
            `;

            ui.conversation.appendChild(div);
            ui.conversation.scrollTop = ui.conversation.scrollHeight;
            return id;
        }

        window.removeThinkingIndicator = function(id) {
            const el = document.getElementById(id);
            if (el) el.remove();
        }

        function addMessageToLog(sender, text) {
            if (sender === "Dr. H") {
                const cleanedText = cleanMedicalResponse(text);
                const contentId = 'response-content-' + Date.now();

                const div = document.createElement('div');
                div.className = "bg-white/90 dark:bg-gemini-800/90 backdrop-blur-sm p-6 rounded-2xl border border-slate-200 dark:border-blue-500/30 shadow-lg dark:shadow-2xl animate-fade-in relative overflow-hidden mb-4 max-w-4xl mr-auto";

                div.innerHTML = `
                    <div class="space-y-4">
                        <div class="flex items-start gap-4">
                            <div class="w-10 h-10 rounded-xl bg-blue-600/20 border border-blue-500/30 flex items-center justify-center flex-shrink-0">
                                <span class="material-symbols-outlined text-blue-600 dark:text-blue-400">smart_toy</span>
                            </div>
                            <div class="flex-1 min-w-0">
                                <div class="flex items-center justify-between mb-2">
                                    <h3 class="font-bold text-slate-800 dark:text-white text-sm uppercase tracking-wider">Dr. Holtkamp Analysis</h3>
                                    <div class="flex items-center gap-2">
                                        <button onclick="copyResponse('${contentId}')" class="text-slate-500 hover:text-black dark:hover:text-white transition-colors p-1 rounded hover:bg-slate-200 dark:hover:bg-slate-700" title="Copy to Clipboard">
                                            <span class="material-symbols-outlined text-[16px]">content_copy</span>
                                        </button>
                                    </div>
                                </div>
                                <div id="${contentId}" class="prose-content text-slate-700 dark:text-slate-300 text-sm leading-relaxed">
                                    ${marked.parse(cleanedText)}
                                </div>
                            </div>
                        </div>
                    </div>
                `;

                ui.conversation.appendChild(div);
                ui.conversation.scrollTop = ui.conversation.scrollHeight;
                return div;

            } else {
                // User Message (Styled to match general look)
                const div = document.createElement('div');
                div.className = "flex justify-end animate-fade-in mb-4";

                const bubble = document.createElement('div');
                bubble.className = "bg-slate-200 dark:bg-slate-700/50 text-slate-800 dark:text-slate-200 px-5 py-3 rounded-2xl rounded-tr-sm max-w-[85%] border border-slate-300 dark:border-slate-600/50 shadow-sm";

                const p = document.createElement('p');
                p.className = "text-sm leading-relaxed whitespace-pre-wrap font-medium";
                p.textContent = text; // Safe injection

                bubble.appendChild(p);
                div.appendChild(bubble);
                ui.conversation.appendChild(div);
                ui.conversation.scrollTop = ui.conversation.scrollHeight;
                return div;
            }
        }

        function drawVisualizer() {
            if (currentState !== STATE.LISTENING) {
                // Clear canvas or show static line
                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
                ui.visualizerContainer.style.opacity = '0.3';
                animationFrame = requestAnimationFrame(drawVisualizer);
                return;
            }

            ui.visualizerContainer.style.opacity = '1';

            if (analyser) {
                analyser.getByteFrequencyData(dataArray);

                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
                const barWidth = (canvas.width / dataArray.length) * 2.5;
                let barHeight;
                let x = 0;

                for(let i = 0; i < dataArray.length; i++) {
                    barHeight = dataArray[i] / 2;

                    // Gradient for Bloomberg Feel (Blue/Teal)
                    const gradient = canvasCtx.createLinearGradient(0, canvas.height - barHeight, 0, canvas.height);
                    gradient.addColorStop(0, '#3b82f6'); // Blue 500
                    gradient.addColorStop(1, '#6366f1'); // Indigo 500

                    canvasCtx.fillStyle = gradient;
                    canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

                    x += barWidth + 1;
                }
            }
            animationFrame = requestAnimationFrame(drawVisualizer);
        }

        // Start visualizer loop immediately
        drawVisualizer();

        // --- State Management ---

        window.updateState = function(newState) {
            currentState = newState;
            // ui.statusText.innerText = newState; // Removed status text
            
            ui.btn.className = "w-10 h-10 rounded-full bg-slate-200 dark:bg-slate-700 hover:bg-slate-300 dark:hover:bg-slate-600 flex items-center justify-center transition-colors flex-shrink-0 group";
            ui.icon.className = "material-symbols-outlined text-slate-600 dark:text-slate-300 group-hover:text-black dark:group-hover:text-white transition-colors";
            ui.icon.innerText = "record_voice_over"; // Default icon

            if (newState === STATE.THINKING || newState === STATE.SPEAKING || newState === STATE.GENERATING_VOICE) {
                ui.interactionText.classList.remove('text-red-500', 'text-amber-500');
                ui.interactionText.classList.add('text-slate-500');
            }

            switch (newState) {
                case STATE.IDLE:
                    // ui.statusDot.className = "w-2 h-2 rounded-full bg-slate-500"; // Removed
                    if (!ui.interactionText.classList.contains('text-amber-500')) {
                        ui.interactionText.innerText = "Ready";
                    }
                    break;
                    
                case STATE.LISTENING:
                    // ui.statusDot.className = "w-2 h-2 rounded-full bg-red-500 animate-pulse";
                    ui.interactionText.innerText = "Listening...";
                    ui.icon.innerText = "stop"; 
                    ui.btn.className = "w-10 h-10 rounded-full bg-red-500 flex items-center justify-center transition-colors flex-shrink-0 animate-pulse shadow-lg shadow-red-900/50";
                    ui.icon.className = "material-symbols-outlined text-white";
                    break;
                    
                case STATE.THINKING:
                    // ui.statusDot.className = "w-2 h-2 rounded-full bg-blue-500 animate-bounce";
                    ui.interactionText.innerText = "Consulting...";
                    break;

                case STATE.GENERATING_VOICE:
                    // ui.statusDot.className = "w-2 h-2 rounded-full bg-indigo-500 animate-pulse";
                    ui.interactionText.innerText = "Generating Voice...";
                    break;
                    
                case STATE.SPEAKING:
                    // ui.statusDot.className = "w-2 h-2 rounded-full bg-green-500 animate-pulse";
                    ui.interactionText.innerText = "Speaking...";
                    // Change button to stop/pause
                    ui.icon.innerText = "stop_circle";
                    ui.btn.className = "w-10 h-10 rounded-full bg-slate-200 dark:bg-slate-700 hover:bg-slate-300 dark:hover:bg-slate-600 flex items-center justify-center transition-colors flex-shrink-0 group border border-slate-300 dark:border-slate-500";
                    break;
            }
        }

    </script>
</body>
</html>
