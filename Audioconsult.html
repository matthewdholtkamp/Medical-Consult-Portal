<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. H - Native Audio Dialog</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        gemini: {
                            800: '#1e293b',
                            900: '#0f172a',
                        }
                    }
                }
            }
        }
    </script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Google Icons -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />

    <style>
        body { font-family: 'Inter', sans-serif; background-color: #0f172a; }

        /* Audio Pulse Animation */
        @keyframes pulse-ring {
            0% { transform: scale(0.8); opacity: 0.5; }
            100% { transform: scale(2.2); opacity: 0; }
        }
        
        .pulse-active::before {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        
        .pulse-active::after {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
            animation-delay: 0.5s;
        }

        @keyframes think-glow {
            0%, 100% { box-shadow: 0 0 20px rgba(168, 85, 247, 0.2); border-color: rgba(168, 85, 247, 0.5); }
            50% { box-shadow: 0 0 40px rgba(168, 85, 247, 0.6); border-color: rgba(168, 85, 247, 1); }
        }
        .thinking-active {
            animation: think-glow 2s infinite;
        }

        .background-overlay {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle at 2px 2px, rgba(255,255,255,0.05) 1px, transparent 0);
            background-size: 32px 32px;
            opacity: 0.5; 
            pointer-events: none; 
        }

        .audio-bar {
            width: 4px;
            background: #60a5fa;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
    </style>
</head>

<body class="text-gray-200 h-screen overflow-hidden flex flex-col relative selection:bg-blue-500 selection:text-white">

    <div class="background-overlay"></div>

    <!-- Ambient Glow -->
    <div class="absolute inset-0 pointer-events-none overflow-hidden">
        <div class="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-[600px] h-[600px] bg-blue-600/10 rounded-full blur-3xl"></div>
    </div>

    <!-- Header -->
    <header class="h-16 flex items-center justify-between px-6 z-20 border-b border-white/5 bg-gemini-900/50 backdrop-blur-sm">
        <div class="flex items-center gap-3">
            <div class="w-8 h-8 rounded-lg bg-gradient-to-br from-blue-500 to-indigo-600 flex items-center justify-center shadow-lg shadow-blue-500/20">
                <span class="material-symbols-outlined text-white text-[20px]">medical_services</span>
            </div>
            <div>
                <h1 class="font-bold text-slate-100 text-sm tracking-wide">Dr. Holtkamp</h1>
                <p class="text-[10px] text-slate-500 uppercase tracking-wider font-medium">Native Audio Dialog</p>
            </div>
        </div>
        <div id="connection-status" class="flex items-center gap-2 px-3 py-1 rounded-full bg-slate-800 border border-slate-700">
            <div id="status-dot" class="w-2 h-2 rounded-full bg-red-500"></div>
            <span id="status-text" class="text-xs text-slate-400 font-mono">DISCONNECTED</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="flex-1 flex flex-col items-center justify-center relative z-10 p-6">
        
        <div id="visualizer-container" class="relative w-64 h-64 mb-16 flex items-center justify-center">
            <div id="pulse-layer" class="absolute inset-0 rounded-full"></div>
            
            <button onclick="toggleConnection()" id="main-mic-btn" class="relative w-40 h-40 bg-slate-800 rounded-full border-2 border-slate-700 shadow-2xl flex items-center justify-center transition-all duration-300 hover:scale-105 group z-20 focus:outline-none focus:ring-4 focus:ring-blue-500/30">
                <span class="material-symbols-outlined text-6xl text-slate-400 group-hover:text-blue-400" id="mic-icon">power_settings_new</span>
            </button>

            <div class="absolute -bottom-12 w-full text-center">
                <span id="interaction-status" class="text-sm font-bold tracking-widest text-slate-500 uppercase">Tap Power to Connect</span>
            </div>
        </div>

        <!-- Transcript Logs -->
        <div class="w-full max-w-2xl text-center space-y-4">
            <div id="transcript-log" class="text-slate-400 text-sm italic font-medium h-12 flex items-center justify-center px-4 overflow-hidden text-center">
                Click the power icon and allow microphone access to begin.
            </div>
            
            <div class="flex items-center justify-center gap-1 h-8">
                <div class="audio-bar h-2"></div>
                <div class="audio-bar h-4"></div>
                <div class="audio-bar h-3"></div>
                <div class="audio-bar h-6"></div>
                <div class="audio-bar h-2"></div>
            </div>
        </div>

    </main>

    <footer class="p-4 text-center text-slate-600 text-xs z-10 relative">
        <p>Expert Medical AI Consult. Strictly Evidence-Based. No PHI.</p>
    </footer>

    <script type="module">
        // --- Configuration ---
        const API_KEY = "AIzaSyD3GmvOlwNBSctv8Xx_r0XcorQhugcC3hY"; 
        const MODEL_ID = "gemini-2.5-flash-native-audio-preview-12-2025";
        const WS_URL = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key=${API_KEY}`;

        // --- Dr. Holtkamp System Instruction ---
        const SYSTEM_INSTRUCTION = `Respond as Dr. Holtkamp, Expert Medical Educator. 
        Context: You are speaking via high-fidelity real-time audio.
        Tone: Professional, authoritative, analytically rigorous. 
        Style: Oral consult format. Be concise.
        Evidence: Use current medical guidelines (AHA, ACC, IDSA, etc.).
        Barge-in: You expect to be interrupted. If the doctor speaks, stop your current thought and listen.`;

        // --- Audio Variables ---
        let audioContext;
        let micStream;
        let processor;
        let socket;
        let isConnected = false;
        let playbackQueue = [];
        let scheduledTime = 0;

        const ui = {
            btn: document.getElementById('main-mic-btn'),
            icon: document.getElementById('mic-icon'),
            pulse: document.getElementById('pulse-layer'),
            statusText: document.getElementById('status-text'),
            statusDot: document.getElementById('status-dot'),
            interactionText: document.getElementById('interaction-status'),
            transcript: document.getElementById('transcript-log'),
            bars: document.querySelectorAll('.audio-bar')
        };

        // --- Connection Management ---

        window.toggleConnection = async function() {
            if (isConnected) {
                disconnect();
            } else {
                connect();
            }
        };

        async function connect() {
            if (API_KEY === "PASTE_YOUR_KEY_HERE" || API_KEY === "") {
                ui.transcript.innerText = "Error: API Key missing in code.";
                return;
            }

            ui.transcript.innerText = "Requesting System Access...";
            ui.interactionText.innerText = "Connecting...";
            ui.btn.classList.add('thinking-active');

            try {
                // 1. Setup Audio Context First (User gesture required)
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                scheduledTime = audioContext.currentTime;

                // 2. Request Microphone
                try {
                    micStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true } 
                    });
                } catch (micErr) {
                    throw new Error("Microphone Denied. Please check browser permissions.");
                }

                // 3. Connect WebSocket
                socket = new WebSocket(WS_URL);
                socket.onopen = onWsOpen;
                socket.onmessage = onWsMessage;
                socket.onclose = onWsClose;
                socket.onerror = (e) => {
                    ui.transcript.innerText = "Connection Blocked. Verify API Key settings & Referrer Policy.";
                };

                setupMicProcessing();

            } catch (err) {
                console.error("Connection failed:", err);
                ui.transcript.innerText = err.message;
                disconnect();
            }
        }

        function disconnect() {
            isConnected = false;
            if (socket) socket.close();
            if (micStream) micStream.getTracks().forEach(t => t.stop());
            if (audioContext && audioContext.state !== 'closed') audioContext.close();
            
            ui.statusDot.className = "w-2 h-2 rounded-full bg-red-500";
            ui.statusText.innerText = "DISCONNECTED";
            ui.icon.innerText = "power_settings_new";
            ui.icon.classList.remove('text-blue-400');
            ui.btn.classList.remove('thinking-active');
            ui.interactionText.innerText = "Tap Power to Connect";
            ui.pulse.className = "absolute inset-0 rounded-full";
            stopAllAudio();
        }

        // --- WebSocket Handlers ---

        function onWsOpen() {
            isConnected = true;
            ui.statusDot.className = "w-2 h-2 rounded-full bg-green-500 animate-pulse";
            ui.statusText.innerText = "LIVE";
            ui.icon.innerText = "mic";
            ui.icon.classList.add('text-blue-400');
            ui.btn.classList.remove('thinking-active');
            ui.interactionText.innerText = "Dr. H is Listening";
            ui.transcript.innerText = "System Live. You can speak now.";
            ui.pulse.className = "absolute inset-0 rounded-full pulse-active";

            // Send Setup Frame
            const setup = {
                setup: {
                    model: `models/${MODEL_ID}`,
                    systemInstruction: { parts: [{ text: SYSTEM_INSTRUCTION }] },
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            voiceConfig: { prebuiltVoiceConfig: { voiceName: "Fenrir" } }
                        }
                    }
                }
            };
            socket.send(JSON.stringify(setup));
        }

        function onWsMessage(event) {
            if (typeof event.data === 'string') {
                const response = JSON.parse(event.data);
                
                // Handle Audio Output
                if (response.serverContent?.modelTurn?.parts) {
                    const parts = response.serverContent.modelTurn.parts;
                    parts.forEach(part => {
                        if (part.inlineData && part.inlineData.mimeType.includes('audio')) {
                            const raw = atob(part.inlineData.data);
                            const buffer = new Uint8Array(raw.length);
                            for(let i=0; i<raw.length; i++) buffer[i] = raw.charCodeAt(i);
                            queueAudioChunk(buffer.buffer);
                        }
                    });
                }

                // Handle Turn Interruption (Barge-in)
                if (response.serverContent?.interrupted) {
                    stopAllAudio();
                }
            }
        }

        function onWsClose() {
            console.log("WebSocket Closed");
            disconnect();
        }

        // --- Audio Processing (Input) ---

        function setupMicProcessing() {
            const source = audioContext.createMediaStreamSource(micStream);
            processor = audioContext.createScriptProcessor(2048, 1, 1);

            processor.onaudioprocess = (e) => {
                if (!isConnected || socket.readyState !== WebSocket.OPEN) return;

                const inputData = e.inputBuffer.getChannelData(0);
                
                // Visualization logic
                let sum = 0;
                for(let i=0; i<inputData.length; i++) sum += inputData[i] * inputData[i];
                const rms = Math.sqrt(sum / inputData.length);
                updateBars(rms);

                // Convert to 16-bit PCM
                const pcmData = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    pcmData[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7FFF;
                }

                // Send to Gemini
                const base64 = btoa(String.fromCharCode(...new Uint8Array(pcmData.buffer)));
                const frame = {
                    realtime_input: {
                        media_chunks: [{
                            data: base64,
                            mime_type: "audio/pcm;rate=16000"
                        }]
                    }
                };
                socket.send(JSON.stringify(frame));
            };

            source.connect(processor);
            processor.connect(audioContext.destination);
        }

        // --- Audio Playback (Output) ---

        async function queueAudioChunk(arrayBuffer) {
            // Convert Int16 PCM to Float32 for Web Audio API
            const int16Array = new Int16Array(arrayBuffer);
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0;
            }

            const audioBuffer = audioContext.createBuffer(1, float32Array.length, 16000);
            audioBuffer.getChannelData(0).set(float32Array);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            const startTime = Math.max(scheduledTime, audioContext.currentTime);
            source.start(startTime);
            scheduledTime = startTime + audioBuffer.duration;
            
            playbackQueue.push(source);
        }

        function stopAllAudio() {
            playbackQueue.forEach(src => {
                try { src.stop(); } catch(e) {}
            });
            playbackQueue = [];
            scheduledTime = audioContext.currentTime;
        }

        function updateBars(rms) {
            ui.bars.forEach((bar, i) => {
                const scale = (i + 1) * 2;
                const h = Math.min(32, 4 + (rms * 100 * scale));
                bar.style.height = `${h}px`;
            });
        }

    </script>
</body>
</html>
