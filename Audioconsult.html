<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. H - Native Audio Dialog</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        gemini: {
                            800: '#1e293b',
                            900: '#0f172a',
                        }
                    },
                    animation: {
                        'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',
                    }
                }
            }
        }
    </script>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Google Icons -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />

    <style>
        body { font-family: 'Inter', sans-serif; background-color: #0f172a; }

        /* Audio Pulse Animation */
        @keyframes pulse-ring {
            0% { transform: scale(0.8); opacity: 0.5; }
            100% { transform: scale(2.2); opacity: 0; }
        }
        
        .pulse-active::before {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        
        .pulse-active::after {
            content: '';
            position: absolute;
            left: 0; top: 0; right: 0; bottom: 0;
            border-radius: 50%;
            border: 2px solid #60a5fa;
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
            animation-delay: 0.5s;
        }

        @keyframes think-glow {
            0%, 100% { box-shadow: 0 0 20px rgba(168, 85, 247, 0.2); border-color: rgba(168, 85, 247, 0.5); }
            50% { box-shadow: 0 0 40px rgba(168, 85, 247, 0.6); border-color: rgba(168, 85, 247, 1); }
        }
        .thinking-active {
            animation: think-glow 2s infinite;
        }

        .background-overlay {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle at 2px 2px, rgba(255,255,255,0.05) 1px, transparent 0);
            background-size: 32px 32px;
            opacity: 0.5; 
            pointer-events: none; 
        }

        .audio-bar {
            width: 4px;
            background: #60a5fa;
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        /* Debug Panel Styles */
        .debug-row { display: flex; justify-content: space-between; font-family: monospace; font-size: 10px; color: #94a3b8; border-bottom: 1px solid #334155; padding: 2px 0; }
        .debug-row span:last-child { color: #e2e8f0; font-weight: 600; }
        .debug-section { margin-bottom: 8px; }
        .debug-title { font-size: 10px; font-weight: bold; color: #64748b; text-transform: uppercase; margin-bottom: 2px; }
        .debug-log { font-family: monospace; font-size: 9px; color: #a5f3fc; background: #164e63; padding: 2px 4px; border-radius: 2px; margin-top: 2px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }
    </style>
</head>

<body class="text-gray-200 h-screen overflow-hidden flex flex-col relative selection:bg-blue-500 selection:text-white">

    <div class="background-overlay"></div>

    <!-- Ambient Glow -->
    <div class="absolute inset-0 pointer-events-none overflow-hidden">
        <div class="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-[600px] h-[600px] bg-blue-600/10 rounded-full blur-3xl"></div>
    </div>

    <!-- Demo Mode Warning -->
    <div id="demo-warning" class="bg-amber-500/10 border-b border-amber-500/20 px-4 py-1 text-center">
        <p class="text-[10px] font-bold text-amber-500 uppercase tracking-widest">
            Demo Mode • Client-Side API Key • Not for Production
        </p>
    </div>

    <!-- Header -->
    <header class="h-16 flex items-center justify-between px-6 z-20 border-b border-white/5 bg-gemini-900/50 backdrop-blur-sm">
        <div class="flex items-center gap-3">
            <div class="w-8 h-8 rounded-lg bg-gradient-to-br from-blue-500 to-indigo-600 flex items-center justify-center shadow-lg shadow-blue-500/20">
                <span class="material-symbols-outlined text-white text-[20px]">medical_services</span>
            </div>
            <div>
                <h1 class="font-bold text-slate-100 text-sm tracking-wide">Dr. Holtkamp</h1>
                <p class="text-[10px] text-slate-500 uppercase tracking-wider font-medium">Native Audio Dialog</p>
            </div>
        </div>
        <div id="connection-status-badge" class="flex items-center gap-2 px-3 py-1 rounded-full bg-slate-800 border border-slate-700 transition-colors cursor-pointer" onclick="toggleDebugPanel()">
            <div id="status-dot" class="w-2 h-2 rounded-full bg-slate-500"></div>
            <span id="status-text" class="text-xs text-slate-400 font-mono font-bold">DISCONNECTED</span>
            <span class="material-symbols-outlined text-[10px] text-slate-500 ml-1">expand_more</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="flex-1 flex flex-col items-center justify-center relative z-10 p-6">
        
        <!-- Unified Debug Overlay -->
        <div id="debug-panel" class="absolute top-2 right-2 w-80 bg-slate-900/95 border border-slate-700 backdrop-blur-md rounded-xl p-3 z-50 shadow-2xl transition-all duration-300 transform translate-x-0 hidden md:block">
            <div class="flex items-center justify-between mb-2 border-b border-slate-700 pb-2">
                <div class="flex items-center gap-2 text-blue-400">
                    <span class="material-symbols-outlined text-sm">terminal</span>
                    <h3 class="text-xs font-bold uppercase tracking-wider">System Telemetry</h3>
                </div>
                <div class="flex gap-2">
                     <button onclick="copyDebugInfo()" title="Copy Debug Info" class="text-slate-400 hover:text-white">
                        <span class="material-symbols-outlined text-sm">content_copy</span>
                    </button>
                    <button onclick="toggleDebugPanel()" class="text-slate-400 hover:text-white">
                        <span class="material-symbols-outlined text-sm">expand_less</span>
                    </button>
                </div>
            </div>

            <!-- Error Region (Only shown on error) -->
            <div id="debug-error-box" class="hidden bg-red-900/20 border border-red-500/30 rounded p-2 mb-3">
                <div class="flex items-center gap-1 text-red-400 mb-1">
                    <span class="material-symbols-outlined text-xs">warning</span>
                    <span class="text-[10px] font-bold uppercase">Critical Failure</span>
                </div>
                <p id="debug-error-msg" class="text-[10px] text-red-300 font-mono break-words leading-tight"></p>
                <div class="flex justify-between mt-1 text-[9px] text-red-400/70 font-mono">
                    <span id="debug-error-code">Code: --</span>
                    <span id="debug-error-phase">Phase: --</span>
                </div>
            </div>

            <div class="space-y-3 max-h-[70vh] overflow-y-auto custom-scroll pr-1">
                <!-- State Section -->
                <div class="debug-section">
                    <div class="debug-title">Connection State</div>
                    <div class="debug-row"><span>Phase</span><span id="tele-phase">DISCONNECTED</span></div>
                    <div class="debug-row"><span>WS ReadyState</span><span id="tele-ws-state">--</span></div>
                    <div class="debug-row"><span>AudioCtx</span><span id="tele-audio-state">--</span></div>
                    <div class="debug-row"><span>Model</span><span class="truncate max-w-[120px]" id="tele-model">--</span></div>
                </div>

                <!-- Counters Section -->
                <div class="debug-section">
                    <div class="debug-title">Traffic Counters</div>
                    <div class="debug-row"><span>Setup Sent</span><span id="cnt-setup">0</span></div>
                    <div class="debug-row"><span>Trigger Sent</span><span id="cnt-trigger">0</span></div>
                    <div class="debug-row"><span>Audio Sent (Chunks)</span><span id="cnt-audio-tx">0</span></div>
                    <div class="debug-row"><span>Audio Rx (Chunks)</span><span id="cnt-audio-rx">0</span></div>
                    <div class="debug-row"><span>Text Rx (Chunks)</span><span id="cnt-text-rx">0</span></div>
                </div>

                <!-- Timing Section -->
                <div class="debug-section">
                    <div class="debug-title">Timestamps (Rel.)</div>
                    <div class="debug-row"><span>Last Msg</span><span id="time-last-msg">--</span></div>
                    <div class="debug-row"><span>Last Audio Rx</span><span id="time-last-audio">--</span></div>
                    <div class="debug-row"><span>Last Text Rx</span><span id="time-last-text">--</span></div>
                </div>

                <!-- Last Server Response (Debug) -->
                <div class="debug-section">
                    <div class="debug-title">Last Server Output</div>
                    <div id="debug-last-output" class="debug-log">--</div>
                </div>

                <!-- Actions -->
                <div class="pt-2 border-t border-slate-700 flex flex-col gap-2">
                    <button onclick="sendTestKick()" id="btn-kick" class="w-full py-1 bg-blue-600/20 hover:bg-blue-600/40 text-blue-400 border border-blue-500/30 rounded text-xs font-mono transition-colors disabled:opacity-50 disabled:cursor-not-allowed" disabled>
                        [TEST] SEND TEXT KICK
                    </button>
                    <button onclick="sendForceSpeak()" id="btn-force-speak" class="w-full py-1 bg-purple-600/20 hover:bg-purple-600/40 text-purple-400 border border-purple-500/30 rounded text-xs font-mono transition-colors disabled:opacity-50 disabled:cursor-not-allowed" disabled>
                        [TEST] FORCE SPEAK & TEXT
                    </button>
                </div>
            </div>
        </div>

        <div id="visualizer-container" class="relative w-64 h-64 mb-16 flex items-center justify-center">
            <div id="pulse-layer" class="absolute inset-0 rounded-full"></div>
            
            <button onclick="toggleConnection()" id="main-mic-btn" class="relative w-40 h-40 bg-slate-800 rounded-full border-2 border-slate-700 shadow-2xl flex items-center justify-center transition-all duration-300 hover:scale-105 group z-20 focus:outline-none focus:ring-4 focus:ring-blue-500/30">
                <span class="material-symbols-outlined text-6xl text-slate-400 group-hover:text-blue-400 transition-colors" id="mic-icon">power_settings_new</span>
            </button>

            <div class="absolute -bottom-12 w-full text-center">
                <span id="interaction-status" class="text-sm font-bold tracking-widest text-slate-500 uppercase transition-colors">Tap Power to Connect</span>
            </div>
        </div>

        <!-- Transcript Logs -->
        <div class="w-full max-w-2xl text-center space-y-4">
            <div id="transcript-log" class="text-slate-400 text-sm italic font-medium h-12 flex items-center justify-center px-4 overflow-hidden text-center transition-colors">
                Click the power icon and allow microphone access to begin.
            </div>
            
            <div class="flex items-center justify-center gap-1 h-8 opacity-50" id="audio-bars-container">
                <div class="audio-bar h-2"></div>
                <div class="audio-bar h-4"></div>
                <div class="audio-bar h-3"></div>
                <div class="audio-bar h-6"></div>
                <div class="audio-bar h-2"></div>
            </div>
        </div>

    </main>

    <footer class="p-4 text-center text-slate-600 text-xs z-10 relative">
        <p>Expert Medical AI Consult. Strictly Evidence-Based. No PHI.</p>
    </footer>

    <script type="module">
        import { API_KEYS } from '/Medical-Consult-Portal/js/config.js';

        // --- Configuration ---
        const API_KEY = API_KEYS.ORTHOPEDICS;
        const MODEL_ID = "gemini-2.5-flash-native-audio-preview-12-2025";
        const WS_URL = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key=${API_KEY}`;

        // --- Connection State Machine ---
        const STATE = {
            DISCONNECTED: 'DISCONNECTED',
            CONNECTING: 'CONNECTING',
            CONFIGURING: 'CONFIGURING',
            LIVE: 'LIVE',
            ERROR: 'ERROR'
        };

        // --- Dr. Holtkamp System Instruction ---
        const SYSTEM_INSTRUCTION = `Respond as Dr. Holtkamp, Expert Medical Educator. 
        Context: You are speaking via high-fidelity real-time audio.
        Tone: Professional, authoritative, analytically rigorous. 
        Style: Oral consult format. Be concise.
        Evidence: Use current medical guidelines (AHA, ACC, IDSA, etc.).
        Barge-in: You expect to be interrupted. If the doctor speaks, stop your current thought and listen.`;

        const GREETINGS = [
            "Hey Doc, what's up?",
            "Dr. Holtkamp here. How can I help?",
            "Good to see you, Doctor. Ready for rounds?",
            "Hello Doctor. I'm listening.",
            "Hi Doc. What's the situation?",
            "Dr. Holtkamp online. What are we working on?",
            "Greetings, Doctor. Ready to consult.",
            "Hey there, Doc. What's on your mind?",
            "Doctor, I'm ready. Go ahead.",
            "Hello. Let's solve this case."
        ];

        // --- Global Variables ---
        let audioContext;
        let micStream;
        let processor; // Worklet Node
        let socket;
        let currentState = STATE.DISCONNECTED;
        let playbackQueue = [];
        let scheduledTime = 0;

        // Watchdogs
        let serverFrameTimeout = null;
        let audioFrameTimeout = null;

        // Telemetry Data
        const telemetry = {
            setupSent: 0,
            triggerSent: 0,
            audioChunksSent: 0,
            audioChunksReceived: 0,
            textChunksReceived: 0,
            msgsReceived: 0,
            lastMsgAt: null,
            lastAudioAt: null,
            lastTextAt: null,
            firstFrames: [], // Store first 3 frames for debugging
            lastError: null
        };

        const ui = {
            btn: document.getElementById('main-mic-btn'),
            icon: document.getElementById('mic-icon'),
            pulse: document.getElementById('pulse-layer'),
            badge: document.getElementById('connection-status-badge'),
            statusText: document.getElementById('status-text'),
            statusDot: document.getElementById('status-dot'),
            interactionText: document.getElementById('interaction-status'),
            transcript: document.getElementById('transcript-log'),
            barsContainer: document.getElementById('audio-bars-container'),
            bars: document.querySelectorAll('.audio-bar'),

            // Debug Panel
            debugPanel: document.getElementById('debug-panel'),
            debugErrorBox: document.getElementById('debug-error-box'),
            debugErrorMsg: document.getElementById('debug-error-msg'),
            debugErrorCode: document.getElementById('debug-error-code'),
            debugErrorPhase: document.getElementById('debug-error-phase'),
            debugLastOutput: document.getElementById('debug-last-output'),
            btnKick: document.getElementById('btn-kick'),
            btnForceSpeak: document.getElementById('btn-force-speak'),

            // Telemetry Fields
            telePhase: document.getElementById('tele-phase'),
            teleWsState: document.getElementById('tele-ws-state'),
            teleAudioState: document.getElementById('tele-audio-state'),
            teleModel: document.getElementById('tele-model'),
            cntSetup: document.getElementById('cnt-setup'),
            cntTrigger: document.getElementById('cnt-trigger'),
            cntAudioTx: document.getElementById('cnt-audio-tx'),
            cntAudioRx: document.getElementById('cnt-audio-rx'),
            cntTextRx: document.getElementById('cnt-text-rx'),
            cntMsgsRx: document.getElementById('cnt-msgs-rx'),
            timeLastMsg: document.getElementById('time-last-msg'),
            timeLastAudio: document.getElementById('time-last-audio'),
            timeLastText: document.getElementById('time-last-text')
        };

        // --- UI Logic ---

        window.toggleDebugPanel = function() {
            ui.debugPanel.classList.toggle('hidden');
        };

        function updateTelemetryUI() {
            ui.telePhase.innerText = currentState;
            ui.teleWsState.innerText = socket ? socket.readyState : 'CLOSED';
            ui.teleAudioState.innerText = audioContext ? audioContext.state : 'N/A';
            ui.teleModel.innerText = MODEL_ID.split('-')[2] || 'flash'; // Shorten

            ui.cntSetup.innerText = telemetry.setupSent;
            ui.cntTrigger.innerText = telemetry.triggerSent;
            ui.cntAudioTx.innerText = telemetry.audioChunksSent;
            ui.cntAudioRx.innerText = telemetry.audioChunksReceived;
            ui.cntTextRx.innerText = telemetry.textChunksReceived;
            ui.cntMsgsRx.innerText = telemetry.msgsReceived;

            const now = Date.now();
            ui.timeLastMsg.innerText = telemetry.lastMsgAt ? `${((now - telemetry.lastMsgAt)/1000).toFixed(1)}s ago` : '--';
            ui.timeLastAudio.innerText = telemetry.lastAudioAt ? `${((now - telemetry.lastAudioAt)/1000).toFixed(1)}s ago` : '--';
            ui.timeLastText.innerText = telemetry.lastTextAt ? `${((now - telemetry.lastTextAt)/1000).toFixed(1)}s ago` : '--';

            // Enable Kick button only if we are connected (OPEN)
            const isLive = socket && socket.readyState === WebSocket.OPEN;
            ui.btnKick.disabled = !isLive;
            ui.btnForceSpeak.disabled = !isLive;
        }

        // Run UI loop
        setInterval(updateTelemetryUI, 500);

        function updateState(newState) {
            console.log(`State Transition: ${currentState} -> ${newState}`);
            currentState = newState;
            ui.statusText.innerText = newState;

            // Reset Classes
            ui.statusDot.className = "w-2 h-2 rounded-full";
            ui.badge.className = "flex items-center gap-2 px-3 py-1 rounded-full border transition-colors cursor-pointer";
            ui.icon.classList.remove('text-blue-400', 'text-amber-400', 'text-red-400');
            ui.btn.classList.remove('thinking-active', 'border-red-500', 'border-slate-700', 'border-blue-500');
            ui.pulse.className = "absolute inset-0 rounded-full";
            ui.barsContainer.classList.add('opacity-50');

            switch (newState) {
                case STATE.DISCONNECTED:
                    ui.statusDot.classList.add('bg-slate-500');
                    ui.badge.classList.add('bg-slate-800', 'border-slate-700');
                    ui.icon.innerText = "power_settings_new";
                    ui.btn.classList.add('border-slate-700');
                    ui.interactionText.innerText = "Tap Power to Connect";
                    ui.interactionText.classList.remove('text-blue-400', 'text-red-400');
                    break;

                case STATE.CONNECTING:
                    ui.statusDot.classList.add('bg-amber-500', 'animate-pulse');
                    ui.badge.classList.add('bg-amber-900/20', 'border-amber-500/30');
                    ui.icon.innerText = "settings_input_antenna";
                    ui.icon.classList.add('text-amber-400');
                    ui.btn.classList.add('border-slate-700', 'thinking-active');
                    ui.interactionText.innerText = "Establishing Secure Link...";
                    ui.transcript.innerText = "Handshaking with Gemini Live...";
                    ui.debugErrorBox.classList.add('hidden'); // Clear errors on retry
                    resetTelemetry();
                    break;

                case STATE.CONFIGURING:
                    ui.statusDot.classList.add('bg-blue-500', 'animate-pulse');
                    ui.badge.classList.add('bg-blue-900/20', 'border-blue-500/30');
                    ui.icon.innerText = "downloading";
                    ui.icon.classList.add('text-blue-400');
                    ui.btn.classList.add('border-blue-500', 'thinking-active');
                    ui.interactionText.innerText = "Configuring Audio Stream...";
                    break;

                case STATE.LIVE:
                    ui.statusDot.classList.add('bg-green-500', 'animate-pulse');
                    ui.badge.classList.add('bg-green-900/20', 'border-green-500/30', 'shadow-lg', 'shadow-green-500/10');
                    ui.icon.innerText = "mic";
                    ui.icon.classList.add('text-blue-400');
                    ui.btn.classList.add('border-slate-700');
                    ui.pulse.className = "absolute inset-0 rounded-full pulse-active";
                    ui.interactionText.innerText = "Dr. H is Listening";
                    ui.interactionText.classList.add('text-blue-400');
                    ui.transcript.innerText = "System Live. Audio channel open.";
                    ui.barsContainer.classList.remove('opacity-50');
                    break;

                case STATE.ERROR:
                    ui.statusDot.classList.add('bg-red-500');
                    ui.badge.classList.add('bg-red-900/20', 'border-red-500/30');
                    ui.icon.innerText = "error";
                    ui.icon.classList.add('text-red-400');
                    ui.btn.classList.add('border-red-500');
                    ui.interactionText.innerText = "Connection Failed";
                    ui.interactionText.classList.add('text-red-400');
                    break;
            }
            updateTelemetryUI();
        }

        function reportError(code, reason, msg) {
            console.error(`[ERROR] ${code}: ${msg}`);
            telemetry.lastError = { code, reason, msg, phase: currentState };

            ui.debugErrorMsg.innerText = msg;
            ui.debugErrorCode.innerText = `Code: ${code}`;
            ui.debugErrorPhase.innerText = `Phase: ${telemetry.lastError.phase}`;
            ui.debugErrorBox.classList.remove('hidden');

            // Auto-open panel on error
            ui.debugPanel.classList.remove('hidden');
            updateState(STATE.ERROR);
        }

        function resetTelemetry() {
            telemetry.setupSent = 0;
            telemetry.triggerSent = 0;
            telemetry.audioChunksSent = 0;
            telemetry.audioChunksReceived = 0;
            telemetry.textChunksReceived = 0;
            telemetry.msgsReceived = 0;
            telemetry.lastMsgAt = null;
            telemetry.lastAudioAt = null;
            telemetry.lastTextAt = null;
            telemetry.firstFrames = [];
            telemetry.lastError = null;
            ui.debugLastOutput.innerText = "--";
        }

        window.copyDebugInfo = function() {
            const info = {
                state: currentState,
                wsState: socket ? socket.readyState : 'NULL',
                audioCtxState: audioContext ? audioContext.state : 'NULL',
                telemetry: telemetry,
                userAgent: navigator.userAgent
            };
            navigator.clipboard.writeText(JSON.stringify(info, null, 2)).then(() => {
                const btn = document.querySelector('button[title="Copy Debug Info"]');
                btn.classList.add('text-green-400');
                setTimeout(() => btn.classList.remove('text-green-400'), 1000);
            });
        };

        window.sendTestKick = function() {
            if (!socket || socket.readyState !== WebSocket.OPEN) return;
            const msg = {
                clientContent: {
                    turns: [{
                        role: "user",
                        parts: [{ text: "System check. Confirm audio link established." }]
                    }],
                    turnComplete: true
                }
            };
            socket.send(JSON.stringify(msg));
            console.log("Kick message sent");
        };

        window.sendForceSpeak = function() {
            if (!socket || socket.readyState !== WebSocket.OPEN) return;
            const msg = {
                clientContent: {
                    turns: [{
                        role: "user",
                        parts: [{ text: "Reply with BOTH: (1) the exact text 'ACK', and (2) speak it out loud." }]
                    }],
                    turnComplete: true
                }
            };
            socket.send(JSON.stringify(msg));
            console.log("Force Speak message sent");
        };

        // --- Connection Management ---

        window.toggleConnection = async function() {
            if (currentState === STATE.DISCONNECTED || currentState === STATE.ERROR) {
                connect();
            } else {
                disconnect();
            }
        };

        async function connect() {
            if (API_KEY === "PASTE_YOUR_KEY_HERE" || !API_KEY) {
                reportError("AUTH_FAIL", "Missing Key", "API Key not found in config.");
                return;
            }

            updateState(STATE.CONNECTING);

            try {
                // 1. Setup Audio Context (Native Rate)
                audioContext = new (window.AudioContext || window.webkitAudioContext)();

                // Explicit Resume (Browser Autoplay Policy)
                await audioContext.resume();
                scheduledTime = audioContext.currentTime;

                // 2. Load Worklet
                try {
                    await audioContext.audioWorklet.addModule('js/audio-processor.js');
                } catch (e) {
                    throw new Error(`Audio Worklet failed to load: ${e.message}`);
                }

                // 3. Request Microphone
                try {
                    micStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });
                } catch (micErr) {
                    throw new Error("Microphone access denied. Please allow permissions.");
                }

                // 4. WebSocket Handshake
                socket = new WebSocket(WS_URL);

                socket.onopen = onWsOpen;
                socket.onmessage = onWsMessage;
                socket.onclose = onWsClose;
                socket.onerror = (e) => console.error("WS Error Event:", e);

                // 5. Start Mic Processing (but don't send yet until Open)
                setupMicProcessing();

                // 6. Start Watchdogs
                startWatchdogs();

            } catch (err) {
                disconnect(false);
                reportError("CLIENT_ERR", "Exception", err.message);
            }
        }

        function startWatchdogs() {
            // Watchdog 1: 5s timeout for ANY server frame
            serverFrameTimeout = setTimeout(() => {
                if (telemetry.msgsReceived === 0 && currentState !== STATE.ERROR) {
                    disconnect(false);
                    reportError("TIMEOUT_NO_RESP", "No Server Frames", "Server did not respond within 5s of connection.");
                }
            }, 5000);

            // Watchdog 2: 10s timeout for AUDIO frames
            audioFrameTimeout = setTimeout(() => {
                if (telemetry.audioChunksReceived === 0 && currentState !== STATE.ERROR) {
                    let errMsg = "Connected, but received no audio frames within 10s.";
                    let errCode = "TIMEOUT_NO_AUDIO";

                    if (telemetry.textChunksReceived > 0) {
                        errMsg = "Model responding with TEXT ONLY. Audio configuration failed.";
                        errCode = "TIMEOUT_TEXT_ONLY";
                    } else if (telemetry.msgsReceived > 0) {
                         errMsg = "Server sending messages but NO MODEL OUTPUT (Text or Audio).";
                         errCode = "TIMEOUT_EMPTY_FRAMES";
                    }

                    disconnect(false);
                    reportError(errCode, "No Audio Output", errMsg);
                }
            }, 10000);
        }

        function disconnect(isClean = true) {
            // Clear Watchdogs
            clearTimeout(serverFrameTimeout);
            clearTimeout(audioFrameTimeout);

            // Cleanup Logic
            if (socket) {
                socket.close(1000, "User Disconnect");
                socket = null;
            }
            if (micStream) {
                micStream.getTracks().forEach(t => t.stop());
                micStream = null;
            }
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            stopAllAudio();

            if (isClean) {
                updateState(STATE.DISCONNECTED);
            }
        }

        // --- WebSocket Handlers ---

        function onWsOpen() {
            console.log("WebSocket Opened");
            updateState(STATE.CONFIGURING);

            // 1. Send Setup
            const setup = {
                setup: {
                    model: `models/${MODEL_ID}`,
                    generationConfig: {
                        // Request BOTH modalities for debugging
                        responseModalities: ["AUDIO", "TEXT"],
                        speechConfig: {
                            voiceConfig: { prebuiltVoiceConfig: { voiceName: "Fenrir" } }
                        }
                    },
                    systemInstruction: { parts: [{ text: SYSTEM_INSTRUCTION }] },
                }
            };
            socket.send(JSON.stringify(setup));
            telemetry.setupSent++;

            // 2. Send Initial Trigger (Start Conversation)
            const randomGreeting = GREETINGS[Math.floor(Math.random() * GREETINGS.length)];
            const trigger = {
                clientContent: {
                    turns: [{
                        role: "user",
                        parts: [{ text: `The user has joined. Start immediately by saying: "${randomGreeting}"` }]
                    }],
                    turnComplete: true
                }
            };
            socket.send(JSON.stringify(trigger));
            telemetry.triggerSent++;
        }

        function onWsMessage(event) {
            telemetry.msgsReceived++;
            telemetry.lastMsgAt = Date.now();

            if (typeof event.data === 'string') {
                let response;
                try {
                    response = JSON.parse(event.data);
                } catch (e) {
                    console.error("Non-JSON frame received");
                    return;
                }

                // Log first 3 frames
                if (telemetry.firstFrames.length < 3) {
                    telemetry.firstFrames.push(response);
                    console.log("Server Frame:", response);
                }

                // Check for Global Errors
                if (response.error) {
                    disconnect(false);
                    reportError(response.error.code, response.error.status, response.error.message);
                    return;
                }

                // Check for Server Content (Model Turns)
                if (response.serverContent?.modelTurn?.parts) {
                    const parts = response.serverContent.modelTurn.parts;
                    let hasAudio = false;
                    let hasText = false;
                    let logText = "";

                    parts.forEach(part => {
                        // 1. Audio
                        if (part.inlineData && part.inlineData.mimeType.includes('audio')) {
                            hasAudio = true;
                            // Convert Base64 -> Float32 -> Play
                            const raw = atob(part.inlineData.data);
                            const buffer = new Uint8Array(raw.length);
                            for(let i=0; i<raw.length; i++) buffer[i] = raw.charCodeAt(i);
                            queueAudioChunk(buffer.buffer);
                            logText = "[Audio Chunk]";
                        }
                        // 2. Text
                        else if (part.text) {
                            hasText = true;
                            logText = part.text.substring(0, 30) + (part.text.length > 30 ? "..." : "");
                            console.log("Model Text:", part.text);
                        }
                    });

                    // Update UI Log
                    if (logText) ui.debugLastOutput.innerText = logText;

                    if (hasAudio) {
                        telemetry.audioChunksReceived++;
                        telemetry.lastAudioAt = Date.now();
                        if (currentState !== STATE.LIVE) updateState(STATE.LIVE);
                    }

                    if (hasText) {
                        telemetry.textChunksReceived++;
                        telemetry.lastTextAt = Date.now();
                    }
                }

                // Check for Interruption
                if (response.serverContent?.interrupted) {
                    console.log("Model Interrupted by User");
                    stopAllAudio();
                    ui.debugLastOutput.innerText = "[Interrupted]";
                }
            }
        }

        function onWsClose(event) {
            console.log(`WebSocket Closed: ${event.code} - ${event.reason}`);

            if (event.code === 1000 || event.code === 1005) {
                if(currentState !== STATE.DISCONNECTED) {
                    updateState(STATE.DISCONNECTED);
                }
            } else {
                // Abnormal closure
                const failedPhase = currentState;
                // Don't report if we already reported a more specific error (e.g. timeout)
                if (currentState !== STATE.ERROR) {
                    reportError(event.code, event.reason || "Unknown", `WS Closed during ${failedPhase}`);
                }
            }
        }

        // --- Audio Processing (Input) ---

        function setupMicProcessing() {
            if (!audioContext || !micStream) return;

            const source = audioContext.createMediaStreamSource(micStream);
            const workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');

            workletNode.port.onmessage = (event) => {
                if (socket && socket.readyState === WebSocket.OPEN) {
                    const float32Data = event.data;

                    // 1. Viz
                    let sum = 0;
                    for (let i = 0; i < float32Data.length; i++) sum += float32Data[i] * float32Data[i];
                    const rms = Math.sqrt(sum / float32Data.length);
                    updateBars(rms);

                    // 2. Downsample (Native -> 16000)
                    const downsampled = downsampleTo16k(float32Data, audioContext.sampleRate);

                    // 3. Float32 -> Int16
                    const pcmData = new Int16Array(downsampled.length);
                    for (let i = 0; i < downsampled.length; i++) {
                        pcmData[i] = Math.max(-1, Math.min(1, downsampled[i])) * 0x7FFF;
                    }

                    // 4. Safe Base64 Encode
                    const base64 = arrayBufferToBase64(pcmData.buffer);

                    // 5. Send
                    const frame = {
                        realtimeInput: {
                            mediaChunks: [{
                                data: base64,
                                mimeType: "audio/pcm;rate=16000"
                            }]
                        }
                    };

                    try {
                        socket.send(JSON.stringify(frame));
                        telemetry.audioChunksSent++;
                    } catch (e) {
                        console.error("Socket Send Failed", e);
                    }
                }
            };

            source.connect(workletNode);
            workletNode.connect(audioContext.destination);
            processor = workletNode;
        }

        // Safer Base64 helper (prevents stack overflow on large buffers)
        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        function downsampleTo16k(inputBuffer, inputRate) {
            if (inputRate === 16000) return inputBuffer;
            const ratio = inputRate / 16000;
            const newLength = Math.round(inputBuffer.length / ratio);
            const result = new Float32Array(newLength);
            for (let i = 0; i < newLength; i++) {
                const index = i * ratio;
                const lower = Math.floor(index);
                const upper = Math.ceil(index);
                const weight = index - lower;
                if (upper < inputBuffer.length) {
                    result[i] = inputBuffer[lower] * (1 - weight) + inputBuffer[upper] * weight;
                } else {
                    result[i] = inputBuffer[lower];
                }
            }
            return result;
        }

        // --- Audio Playback (Output) ---

        async function queueAudioChunk(arrayBuffer) {
            // Int16 -> Float32
            const int16Array = new Int16Array(arrayBuffer);
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0;
            }

            const audioBuffer = audioContext.createBuffer(1, float32Array.length, 16000);
            audioBuffer.getChannelData(0).set(float32Array);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            const startTime = Math.max(scheduledTime, audioContext.currentTime);
            source.start(startTime);
            scheduledTime = startTime + audioBuffer.duration;
            
            playbackQueue.push(source);
        }

        function stopAllAudio() {
            playbackQueue.forEach(src => {
                try { src.stop(); } catch(e) {}
            });
            playbackQueue = [];
            if (audioContext) scheduledTime = audioContext.currentTime;
        }

        function updateBars(rms) {
            ui.bars.forEach((bar, i) => {
                const scale = (i + 1) * 2;
                const h = Math.min(48, 4 + (rms * 400 * scale));
                bar.style.height = `${h}px`;
            });
        }

    </script>
</body>
</html>
